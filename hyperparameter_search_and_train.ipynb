{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COPUS Hyperparameter Search and Extended Training\n",
    "\n",
    "This notebook runs a hyperparameter search and then trains the best configuration for 500 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import subprocess\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Set up paths\n",
    "output_dir = Path(\"output/notebook_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Run Hyperparameter Search\n",
    "\n",
    "Run the hyperparameter optimizer with the same settings as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run hyperparameter search\n",
    "cmd = [\n",
    "    \"python\", \"hyperparam_optimizer.py\",\n",
    "    \"--latent_dim\", \"3\",\n",
    "    \"--hidden_dims_search\", \"16,32,64\",\n",
    "    \"--max_layers\", \"3\",\n",
    "    \"--epochs\", \"50\",\n",
    "    \"--mse_weight\", \"0\",\n",
    "    \"--l1_weight\", \"0.5\",\n",
    "    \"--sparse_weight\", \"0.5\",\n",
    "    \"--output_dir\", str(output_dir / \"hyperparam_search\")\n",
    "]\n",
    "\n",
    "print(\"Running hyperparameter search...\")\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "\n",
    "# Execute the command\n",
    "result = subprocess.run(cmd, capture_output=True, text=True, cwd=\"/home/liamb/projects/copus-nn\")\n",
    "\n",
    "# Print output\n",
    "print(\"\\nSTDOUT:\")\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"\\nSTDERR:\")\n",
    "    print(result.stderr)\n",
    "\n",
    "print(f\"\\nExit code: {result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load and Display Results\n",
    "\n",
    "Load the JSON results and display the configuration performance plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results JSON\n",
    "results_file = output_dir / \"hyperparam_search\" / \"hyperparam_results_latent3.json\"\n",
    "with open(results_file) as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Create a summary table\n",
    "summary_data = []\n",
    "for i, result in enumerate(results):\n",
    "    summary_data.append({\n",
    "        'Config': '-'.join(map(str, result['config'])),\n",
    "        'Layers': len(result['config']),\n",
    "        'Params': result['model_info']['total_params'],\n",
    "        'Final Loss': result['final_test_loss'],\n",
    "        'Best Loss': result['best_test_loss']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values('Final Loss')\n",
    "\n",
    "print(\"Hyperparameter Search Results (sorted by final loss):\")\n",
    "print(\"=\" * 60)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Find best configuration\n",
    "best_config = results[0]['config']  # Results are already sorted by final_test_loss\n",
    "best_loss = results[0]['final_test_loss']\n",
    "best_params = results[0]['model_info']['total_params']\n",
    "\n",
    "print(f\"\\nBest configuration: {best_config}\")\n",
    "print(f\"Best final loss: {best_loss:.4f}\")\n",
    "print(f\"Best model parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the configuration performance scatter plot\n",
    "scatter_plot_path = output_dir / \"hyperparam_search\" / \"config_performance_latent3.png\"\n",
    "if scatter_plot_path.exists():\n",
    "    print(\"Configuration Performance Scatter Plot:\")\n",
    "    print(\"=\" * 50)\n",
    "    display(Image(filename=str(scatter_plot_path)))\n",
    "else:\n",
    "    print(f\"Plot not found: {scatter_plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the training progress plot\n",
    "progress_plot_path = output_dir / \"hyperparam_search\" / \"hyperparam_search_latent3.png\"\n",
    "if progress_plot_path.exists():\n",
    "    print(\"Training Progress Plot:\")\n",
    "    print(\"=\" * 30)\n",
    "    display(Image(filename=str(progress_plot_path)))\n",
    "else:\n",
    "    print(f\"Plot not found: {progress_plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train Best Configuration for 500 Epochs\n",
    "\n",
    "Train the best configuration found for 500 epochs to see if we can get better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert best config to hidden_dims string\n",
    "best_config_str = ','.join(map(str, best_config))\n",
    "print(f\"Training best configuration {best_config} for 500 epochs...\")\n",
    "\n",
    "# Run extended training\n",
    "cmd = [\n",
    "    \"python\", \"train_autoencoder.py\",\n",
    "    \"--latent_dim\", \"3\",\n",
    "    \"--hidden_dims\", best_config_str,\n",
    "    \"--epochs\", \"500\",\n",
    "    \"--batch_size\", \"32\",\n",
    "    \"--initial_lr\", \"0.001\",\n",
    "    \"--eta_min\", \"1e-6\",\n",
    "    \"--output_dir\", str(output_dir / \"extended_training\"),\n",
    "    \"--plot_freq\", \"10\",  # Plot every 10 epochs\n",
    "    \"--save_models\"\n",
    "]\n",
    "\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "\n",
    "# Execute the command\n",
    "result = subprocess.run(cmd, capture_output=True, text=True, cwd=\"/home/liamb/projects/copus-nn\")\n",
    "\n",
    "# Print output\n",
    "print(\"\\nSTDOUT:\")\n",
    "print(result.stdout[-2000:])  # Last 2000 chars to see final results\n",  # Limit output
",
 "if result.stderr:\n",
    "    print(\"\\nSTDERR:\")\n",
    "    print(result.stderr)\n",
    "\n",
    "print(f\"\\nExit code: {result.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Display Extended Training Results\n",
    "\n",
    "Show the training loss plot and final results from the 500-epoch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the extended training loss plot\n",
    "extended_plot_path = output_dir / \"extended_training\" / \"training_progress.png\"\n",
    "if extended_plot_path.exists():\n",
    "    print(\"Extended Training (500 epochs) Loss Plot:\")\n",
    "    print(\"=\" * 45)\n",
    "    display(Image(filename=str(extended_plot_path)))\n",
    "else:\n",
    "    print(f\"Plot not found: {extended_plot_path}\")\n",
    "    \n",
    "    # Check for alternative plot names\n",
    "    alt_paths = list((output_dir / \"extended_training\").glob(\"*.png\"))\n",
    "    if alt_paths:\n",
    "        print(f\"Available plots: {[p.name for p in alt_paths]}\")\n",
    "        # Display the first available plot\n",
    "        display(Image(filename=str(alt_paths[0])))\n",
    "    else:\n",
    "        print(\"No plots found in extended training directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display final training statistics\n",
    "final_stats_path = output_dir / \"extended_training\" / \"final_stats.json\"\n",
    "if final_stats_path.exists():\n",
    "    with open(final_stats_path) as f:\n",
    "        final_stats = json.load(f)\n",
    "    \n",
    "    print(\"Extended Training Final Statistics:\")\n",
    "    print(\"=\" * 35)\n",
    "    print(f\"Final training loss: {final_stats['final_train_loss']:.6f}\")\n",
    "    print(f\"Final test loss: {final_stats['final_test_loss']:.6f}\")\n",
    "    print(f\"Best test loss: {final_stats['best_test_loss']:.6f}\")\n",
    "    print(f\"Total epochs: {final_stats['total_epochs']}\")\n",
    "    print(f\"Training time: {final_stats['training_time_seconds']:.2f} seconds\")\n",
    "else:\n",
    "    print(f\"Final stats not found: {final_stats_path}\")\n",
    "    \n",
    "    # Try to extract final loss from stdout\n",
    "    if \"Final test loss:\" in result.stdout:\n",
    "        lines = result.stdout.split('\\n')\n",
    "        for line in reversed(lines):\n",
    "            if \"Final test loss:\" in line:\n",
    "                print(f\"Extracted from output: {line.strip()}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Compare Results\n",
    "\n",
    "Compare the 50-epoch and 500-epoch results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparison of Results:\")\n",
    "print(\"=\" * 25)\n",
    "print(f\"50-epoch search best loss:  {best_loss:.6f}\")\n",
    "\n",
    "if final_stats_path.exists():\n",
    "    extended_loss = final_stats['final_test_loss']\n",
    "    improvement = best_loss - extended_loss\n",
    "    improvement_pct = (improvement / best_loss) * 100\n",
    "    \n",
    "    print(f\"500-epoch training loss:  {extended_loss:.6f}\")\n",
    "    print(f\"Improvement: {improvement:.6f} ({improvement_pct:.2f}%)\")\n",
    "else:\n",
    "    print(\"Extended training results not available\")\n",
    "\n",
    "print(f\"\\nBest configuration: {best_config}\")\n",
    "print(f\"Model parameters: {best_params}\")\n",
    "print(f\"Training time improvement: 10x more epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook:\n",
    "1. Ran a hyperparameter search across 19 different configurations\n",
    "2. Found the best configuration and visualized the results\n",
    "3. Trained the best configuration for 500 epochs (10x longer)\n",
    "4. Compared the performance improvements\n",
    "\n",
    "The extended training should show improved performance, though with diminishing returns after the initial 50 epochs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}